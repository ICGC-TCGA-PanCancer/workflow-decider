# ------
# inputs,  TODO: need to point these to S3 file
# ------
# key=input_bam_file:type=file:display=F:file_meta_type=application/bam
input_bam_file=${workflow_bundle_dir}/Workflow_Bundle_${workflow-directory-name}/${version}/data/sample_chr22_hg19.bam
# ---------
# filtering, TODO: need actual values here
# ---------
# key=samtools_flag:type=text:display=T:display_name=Samtools filter flags, see http://picard.sourceforge.net/explain-flags.html
samtools_flag=1796
# key=samtools_slots_memory_gigabytes:type=int:display=F:display_name=memory in GB for samtools
samtools_slots_memory_gigabytes=4
# -------
# sorting
# -------
# key=picard_sort_mem:type=int:display=F:display_name=memory in GB for picardtools sort
picard_sort_mem=4
# -------
# fixmate
# -------
# key=picard_fixmate_mem:type=int:display=F:display_name=memory in GB for picardtools fixmate
picard_fixmate_mem=4
# -------
# reorder
# -------
# key=picard_reorder_mem:type=int:display=F:display_name=memory in GB for picardtools reorder
picard_reorder_mem=4
# -------------
# gatk settings
# -------------
# key=gatk_unified_genotyper_mem:type=int:display=F:display_name=memory in GB for GATK genotyper
gatk_unified_genotyper_mem=4
# ----------------
# genome reference
# ----------------
# key=fasta:type=text:display=F:display_name=the reference genome
fasta=${workflow_bundle_dir}/Workflow_Bundle_${workflow-directory-name}/${version}/data/ucsc.hg19.fasta
# key=dbsnp_vcf:type=text:display=F:display_name=the reference genome
dbsnp_vcf=${workflow_bundle_dir}/Workflow_Bundle_${workflow-directory-name}/${version}/data/dbsnp_137.hg19.excluding_sites_after_129.vcf
# ----------------
# general settings
# ----------------
# key=threads:type=int:display=F:display_name=the number of threads to use
threads=4
# the output directory is required even if you specify an output file directly
# key=output_dir:type=text:display=F:display_name=a directory that output files will be put in by default
output_dir=seqware-results
# the output_prefix is a convension and used to specify the root of the absolute output path or an S3 bucket name 
# you should pick a path that is available on all custer nodes and can be written by your user
# key=output_prefix:type=text:display=F:display_name=a prefix before the output_dir
output_prefix=./
# if you uncomment this variable the workflow will provision to this file rather than output_prefix/output_dir/output.vcf
# output_file=s3://bucketname/output.vcf